{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reload:  ./pre-data/1.pickle\n",
      "X_train shape:  (4018, 160, 320, 3) y_train shape:  (4018,)\n",
      "reload:  ./pre-data/2.pickle\n",
      "X_train shape:  (4018, 160, 320, 3) y_train shape:  (4018,)\n",
      "reload:  ./pre-data/3.pickle\n",
      "X_train shape:  (4018, 160, 320, 3) y_train shape:  (4018,)\n",
      "reload:  ./pre-data/4.pickle\n",
      "X_train shape:  (4018, 160, 320, 3) y_train shape:  (4018,)\n"
     ]
    }
   ],
   "source": [
    "# Reload the data\n",
    "\n",
    "def reload_data(pickle_file):\n",
    "    print('reload: ', pickle_file)\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "        pickle_data = pickle.load(f)\n",
    "        X_train = pickle_data['X_train']\n",
    "        y_train = pickle_data['y_train']\n",
    "        del pickle_data  # Free up memory\n",
    "    print('X_train shape: ', X_train.shape, 'y_train shape: ',y_train.shape)\n",
    "    return X_train, y_train\n",
    "\n",
    "X_train1, y_train1 = reload_data('./pre-data/1.pickle')\n",
    "X_train2, y_train2 = reload_data('./pre-data/2.pickle')\n",
    "X_train3, y_train3 = reload_data('./pre-data/3.pickle')\n",
    "X_train4, y_train4 = reload_data('./pre-data/4.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combine data set 1, 2, 3, 4 ...\n",
      "X_train shape:  (16072, 160, 320, 3) y_train shape:  (16072,)\n"
     ]
    }
   ],
   "source": [
    "# Combine the data set 1 and 2\n",
    "X_train = np.concatenate((X_train1, X_train2, X_train3, X_train4))\n",
    "y_train = np.concatenate((y_train1, y_train2, y_train3, y_train4))\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "print('combine data set 1, 2, 3, 4 ...')\n",
    "print('X_train shape: ', X_train.shape, 'y_train shape: ',y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x/255. - 0.5, input_shape=(160, 320, 3)))\n",
    "model.add(Convolution2D(6, 5, 5, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Convolution2D(6, 5, 5, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120))\n",
    "model.add(Dense(84))\n",
    "model.add(Dense(1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12857 samples, validate on 3215 samples\n",
      "Epoch 1/3\n",
      "12857/12857 [==============================] - 82s - loss: 1.8255 - val_loss: 0.0124\n",
      "Epoch 2/3\n",
      "12857/12857 [==============================] - 72s - loss: 0.0125 - val_loss: 0.0107\n",
      "Epoch 3/3\n",
      "12857/12857 [==============================] - 73s - loss: 0.0110 - val_loss: 0.0099\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(X_train, y_train, validation_split=0.2, shuffle=True, nb_epoch=3)\n",
    "\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
