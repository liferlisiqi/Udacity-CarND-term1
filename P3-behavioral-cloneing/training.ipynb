{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D, Dropout\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reload:  ./pre-data/1.pickle\n",
      "X_train shape:  (4018, 160, 320, 3) y_train shape:  (4018,)\n",
      "reload:  ./pre-data/2.pickle\n",
      "X_train shape:  (4018, 160, 320, 3) y_train shape:  (4018,)\n",
      "reload:  ./pre-data/3.pickle\n",
      "X_train shape:  (4018, 160, 320, 3) y_train shape:  (4018,)\n",
      "reload:  ./pre-data/4.pickle\n",
      "X_train shape:  (4018, 160, 320, 3) y_train shape:  (4018,)\n",
      "reload:  ./pre-data/5.pickle\n",
      "X_train shape:  (4018, 160, 320, 3) y_train shape:  (4018,)\n",
      "reload:  ./pre-data/6.pickle\n",
      "X_train shape:  (4018, 160, 320, 3) y_train shape:  (4018,)\n"
     ]
    }
   ],
   "source": [
    "# Reload the data\n",
    "\n",
    "def reload_data(pickle_file):\n",
    "    print('reload: ', pickle_file)\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "        pickle_data = pickle.load(f)\n",
    "        X_train = pickle_data['X_train']\n",
    "        y_train = pickle_data['y_train']\n",
    "        del pickle_data  # Free up memory\n",
    "    print('X_train shape: ', X_train.shape, 'y_train shape: ',y_train.shape)\n",
    "    return X_train, y_train\n",
    "\n",
    "X_train1, y_train1 = reload_data('./pre-data/1.pickle')\n",
    "X_train2, y_train2 = reload_data('./pre-data/2.pickle')\n",
    "X_train3, y_train3 = reload_data('./pre-data/3.pickle')\n",
    "X_train4, y_train4 = reload_data('./pre-data/4.pickle')\n",
    "X_train5, y_train5 = reload_data('./pre-data/5.pickle')\n",
    "X_train6, y_train6 = reload_data('./pre-data/6.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combine data set ...\n"
     ]
    }
   ],
   "source": [
    "# Combine the data set\n",
    "print('combine data set ...')\n",
    "X_train = np.concatenate((X_train1, X_train2, X_train3, X_train4, X_train5, X_train6))\n",
    "y_train = np.concatenate((y_train1, y_train2, y_train3, y_train4, y_train5, y_train6))\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "print('X_train shape: ', X_train.shape, 'y_train shape: ',y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model 1: LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lenet = Sequential()\n",
    "# lenet.add(Lambda(lambda x: x/255. - 0.5, input_shape=(160, 320, 3)))\n",
    "# lenet.add(Cropping2D(cropping=((70, 25), (0, 0))))\n",
    "# lenet.add(Convolution2D(6, 5, 5, activation='relu'))\n",
    "# lenet.add(MaxPooling2D())\n",
    "# lenet.add(Convolution2D(6, 5, 5, activation='relu'))\n",
    "# lenet.add(MaxPooling2D())\n",
    "# lenet.add(Flatten())\n",
    "# lenet.add(Dense(120))\n",
    "# lenet.add(Dense(84))\n",
    "# lenet.add(Dense(1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model 2: Nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvidia = Sequential()\n",
    "nvidia.add(Lambda(lambda x: x/255. - 0.5, input_shape=(80, 160, 3)))\n",
    "nvidia.add(Cropping2D(cropping=((35, 13), (0, 0))))\n",
    "nvidia.add(Convolution2D(24, 3, 3, subsample=(2, 2), activation='relu'))\n",
    "nvidia.add(Convolution2D(36, 3, 3, subsample=(2, 2), activation='relu'))\n",
    "nvidia.add(Convolution2D(48, 3, 3, activation='relu'))\n",
    "nvidia.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "nvidia.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "nvidia.add(Dropout(0.5))\n",
    "nvidia.add(Flatten())\n",
    "nvidia.add(Dense(100))\n",
    "nvidia.add(Dense(50))\n",
    "nvidia.add(Dense(10))\n",
    "nvidia.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 5\n",
    "\n",
    "# Training\n",
    "nvidia.compile(loss='mse', optimizer=Adam(LEARNING_RATE))\n",
    "nvidia.fit(X_train, y_train, validation_split=0.2, shuffle=True, nb_epoch=EPOCHS)\n",
    "nvidia.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
