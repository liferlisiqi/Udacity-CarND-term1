{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D, Dropout\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reload:  ./pre-data.pickle\n",
      "X_train shape:  (24108, 80, 80, 3) y_train shape:  (24108,)\n",
      "X_train shape:  (24108, 80, 80, 3) y_train shape:  (24108,)\n"
     ]
    }
   ],
   "source": [
    "# Reload the data\n",
    "\n",
    "def reload_data(pickle_file):\n",
    "    print('reload: ', pickle_file)\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "        pickle_data = pickle.load(f)\n",
    "        X_train = pickle_data['X_train']\n",
    "        y_train = pickle_data['y_train']\n",
    "        del pickle_data  # Free up memory\n",
    "    return X_train, y_train\n",
    "\n",
    "X_train, y_train = reload_data('./pre-data.pickle')\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "print('X_train shape: ', X_train.shape, 'y_train shape: ',y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model 1: LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lenet = Sequential()\n",
    "# lenet.add(Lambda(lambda x: x/255. - 0.5, input_shape=(160, 320, 3)))\n",
    "# lenet.add(Cropping2D(cropping=((70, 25), (0, 0))))\n",
    "# lenet.add(Convolution2D(6, 5, 5, activation='relu'))\n",
    "# lenet.add(MaxPooling2D())\n",
    "# lenet.add(Convolution2D(6, 5, 5, activation='relu'))\n",
    "# lenet.add(MaxPooling2D())\n",
    "# lenet.add(Flatten())\n",
    "# lenet.add(Dense(120))\n",
    "# lenet.add(Dense(84))\n",
    "# lenet.add(Dense(1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model 2: Nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvidia = Sequential()\n",
    "nvidia.add(Lambda(lambda x: x/255. - 0.5, input_shape=(80, 80, 3)))\n",
    "nvidia.add(Cropping2D(cropping=((35, 13), (0, 0))))\n",
    "nvidia.add(Convolution2D(24, 3, 3, subsample=(2, 2), activation='relu'))\n",
    "nvidia.add(Convolution2D(36, 3, 3, subsample=(2, 2), activation='relu'))\n",
    "nvidia.add(Convolution2D(48, 3, 3, activation='relu'))\n",
    "nvidia.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "nvidia.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "nvidia.add(Dropout(0.5))\n",
    "nvidia.add(Flatten())\n",
    "nvidia.add(Dense(100))\n",
    "nvidia.add(Dense(50))\n",
    "nvidia.add(Dense(10))\n",
    "nvidia.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19286 samples, validate on 4822 samples\n",
      "Epoch 1/5\n",
      "19286/19286 [==============================] - 147s - loss: 0.0133 - val_loss: 0.0116\n",
      "Epoch 2/5\n",
      "19286/19286 [==============================] - 15s - loss: 0.0111 - val_loss: 0.0110\n",
      "Epoch 3/5\n",
      "19286/19286 [==============================] - 15s - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 4/5\n",
      "19286/19286 [==============================] - 16s - loss: 0.0101 - val_loss: 0.0110\n",
      "Epoch 5/5\n",
      "19286/19286 [==============================] - 16s - loss: 0.0099 - val_loss: 0.0108\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 5\n",
    "\n",
    "# Training\n",
    "nvidia.compile(loss='mse', optimizer=Adam(LEARNING_RATE))\n",
    "nvidia.fit(X_train, y_train, validation_split=0.2, shuffle=True, nb_epoch=EPOCHS)\n",
    "nvidia.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
